\section{Servo}
\label{sec:servo}
In this section, we cover specific areas of Servo's design or implementation that make use of Rust
and the impacts and limitations of these features.

\subsection{Rust's syntax}
Rust provides struct and enum types (similar to Standard ML's record types and datatypes~\cite{sml97-definition}) as
well as pattern matching.
These types and associated language features provided two large benefits to Servo over traditional browsers
written in \Cplusplus{}.
First, providing new abstractions and intermediate representations is syntactically easy, so there is very little
pressure to tack additional fields into classes simply to avoid creating a large number of new header and implementation
files.
More importantly, this style of programming that uses pattern matching over concrete types instead of
virtual function calls on a class hierarchy provides a non-trivial performance gain.
Virtual functions can both have an in-memory storage cost associated with the virtual fuction tables (sometimes many thousands of bytes\footnote{\url{https://chromium.googlesource.com/chromium/blink/+/c048c5c7c2578274d82faf96e9ebda4c55e428da}}) but more importantly
incur indirect function call costs.
All C++ browser implementations transform performance-critical code to either use the \lstinline[language=C]{final}
specifier wherever possible or specialize the code in some other way to avoid this cost.

Rust also attempted to stay close to familiar syntax, but did not require full fidelity or easy porting of
programs from languages such as \Cplusplus{}.
This approach has worked well for Rust because it has prevented some of the complexity that arose in
Cyclone~\cite{cyclone} with their attempts to build a safe language that required minimal porting effort
for even complicated C code.

\subsection{Compilation strategy}
Many statically typed implementations of polymorphic languages such as Standard ML of New Jersey~\cite{SMLNJ} and
\ocaml{}~\cite{ocaml-manual-3.0} have used a compilation strategy that optimizes representations of data types when
polymorphic code is monomorphically used, but defaults to a less efficient style otherwise, in order to share
code~\cite{ocaml-repr}.
This strategy reduces code size, but leads to unpredictable performance and code, as changes to a codebase that
either add a new instantiation of a polymorphic function at a given type or, in a modular compilation setting, that
expose a polymorphic function externally, can change the performance of code that is not local to the change being
made.
Monomorphization, as in MLton~\cite{mlton}, instead instantiates each polymorphic code block at each of the types
it is applied agains, and providing predictable output code to developers, at the cost of some code duplication.
This approach, combined with whole-program compilation, has some negative impacts in compilation speed but has resulted
in Rust code that easily matches the sequential speed of its \Cplusplus{} analog without requiring the Servo developers
to become compiler experts.

\subsection{Memory management}
As described in \secref{sec:rust}, Rust has an affine type system that ensures every value is used at
most once.
One result of this fact is that in the more than two years since Servo has been under development, we have
encountered zero use-after-free memory bugs in safe Rust code.
Given that these bugs make up such a large portion of the security vulnerabilities in modern browsers,
we believe that even the additional work required to get Rust code to pass the type checker initially is
justified.

One area for future improvement is related to allocations that are not owned by Rust itself.
Today, we simple wrap raw C pointers in \lstinline[language=Rust]{unsafe} blocks when we need to use a
custom memory alloctor or interoperate with the SpiderMonkey JavaScript engine from Gecko.
We have implemented wrapper types and compiler plugins that check that these are being used correctly,
but these are still a source of bugs and one of our largest areas of unsafe code.

\subsection{Language interoperability}
Clean C interop, both for calling and being called were key for integration with various C libraries and bootstrapping larger projects that we intend to eventually be written entirely in Rust, but not initially. This support also means being able to define structs with exact layout expected by C for APIs like that, intead of writing shim layers.

Would like to have full C++ inlining.

That said, interoperating with native C code often requires raw access to memory allocated in Rust or returns
pointers to memory that was allocated by the C libraries.
Translations to and from these raw pointers requires the use of unsafe code.

\subsection{Intrusive data structures}

Rust's ownership model assumes that there is a single owner for each piece of data.
However, many data structures do not follow that model, in order to provide asymptotic
improvements in access.
For example, a doubly-linked list contains a back pointer to the previous element to aid
in traversals in the opposite direction.
Many optimized hashtable implementations also have both hash-based access to items
and a linked list of all of the keys or values.

\subsection{Libraries and abstractions}

Many high-level languages provide abstractions over I/O, threading, parallelism, and concurrency.
This area is one where we started out with much larger aspirations in Rust but ultimately had to pare back,
for reasons very similar to the reasons that we have avoided GC by default --- it is difficult to provide a
predictable, fast implementation that works across all platforms of many systems features.
For example, thread-local storage (TLS) provides variables that are associated with a given thread.
In the presence of both lightweight (stackless) and full native threads across a variety of architectures, though,
it becomes difficult to understand what the cost of initialization and storage are for this feature.
Even lightweight threads in general, when interacting with a built-in scheduler and generic I/O system that
has to work across a variety of platforms (including Windows!) were too expensive to support in practice and
had to be removed.

Even some basic sharing, such as hash tables and vectors has proven challenging.
For example, most web browsers have implementations of vectors that allow instantiation with a default inline size,
as they have use cases where they create many thousands of vectors, nearly none of which have more than 4~elements.
In that case, removing the extra pointer indirection --- particularly if the values are of less than pointer size ---
can be a significant space savings.
But, these sorts of libraries are more highly optimized for a web browser than for a general-purpose systems language.

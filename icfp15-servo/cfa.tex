%!TEX root = paper.tex
%
\section{Control-Flow Analysis}
\label{sec:cfa}
This section provides a brief background on control-flow analysis (CFA) along with an overview 
of our specific implementation techniques to achieve both acceptable scalability and precision. 
A more general introduction to control-flow analysis, in particular the 0CFA
style that we use, is available in the book by Nielson \etal{}~\cite{principles-prog-analysis}.
For a detailed comparison of modern approaches to control-flow analysis, see Midtgaard's 
comprehensive survey~\cite{midtgaard-cfa-survey}. 

In brief, while many others have implemented control-flow analysis in their
compilers~\cite{serrano:cfa-paradigm,mlton-cfa,sub-zero-cfa}, our analysis is
novel in its tracking of a wider range of values --- including boolean values and 
tuples --- and its lattice coarsening to balance performance and precision.

\subsection{Overview}
A control-flow analysis computes a finite map from all of the variables in a program 
to a conservative abstraction of the values that they can take on during the
execution of the code.
That is, it computes a finite map 
\begin{displaymath}
 \mathcal{V} : \mathtt{VarID} \finmap \mathtt{value}
\end{displaymath}
where the $\mathtt{value}$ type is defined as a recursive datatype similar to
that shown in \figref{fig:values}.
The special $\top$ (\lstinline{TOP}) and $\bot$ (\lstinline{BOT}) elements 
indicate either all possible values or no known values, respectively. 
A \lstinline{TUPLE} value handles both the cases of tuples and ML datatype
representations, which by this point in the compiler have been desugared into
either raw values or tagged tuples.
The \lstinline{LAMBDAS} value is used for a set of variable identifiers, all of
which are guaranteed to be function identifiers.
The \lstinline{BOOL} value tracks the flow of literal boolean values through
the program.
\begin{figure}[t]
\begin{lstlisting}[basicstyle=\ttfamily\scriptsize\color{\cdColor}]
  datatype value
    = TOP
    | TUPLE of value list
    | LAMBDAS of CPS.Var.Set.set
    | BOOL of bool
    | BOT
\end{lstlisting}
\caption{
  Abstract values.
}
\label{fig:values} 
\end{figure}%

As an example, consider the following code:
\begin{lstlisting}[basicstyle=\ttfamily\scriptsize\color{\cdColor}]
let fun double (x) = x+x
    and apply (f, n) = f(n)
in
    apply (double, 2)
end
\end{lstlisting}%
After running CFA on this example, we have
\begin{displaymath}
  \begin{array}{rcl}
    \mathcal{V}(\texttt{f}) & = & \texttt{LAMBDAS(\SET{double})} \\
    \mathcal{V}(\texttt{n}) & = & \top \\
    \mathcal{V}(\texttt{x}) & = & \top
  \end{array}
\end{displaymath}%
These results indicate that the variable \lstinline{f} must be bound to the 
function \lstinline{double}.
This example and the \lstinline{value} representation in \figref{fig:values} do not
track numeric values, which is why \lstinline{n} and \lstinline{x} are mapped to $\top$.
We are planning to track a richer set of values, including datatype-specific values, in the future
in order to enable optimizations beyond the ones discussed in this paper.

\subsection{Implementation}
Our CFA implementation is straightforward and similar in spirit to Serrano's~\cite{serrano:cfa-paradigm}.
We start with an empty map and walk over the intermediate representation of the 
program.
At each expression, we update $\mathcal{V}$ by merging the value-flow information
until we reach a fixed point where the map no longer changes.
The most interesting difference from Serrano's implementation is that
we use our tracked boolean values to avoid merging control-flow information
along arms of conditional expressions that can never be taken.
In our experience, the key to reducing the runtime of control-flow analysis while still
maintaining high precision lies in carefully choosing (and empirically tuning)
the tracked abstraction of values.

\subsubsection{Tuning the lattice}
Each time we evaluate an expression whose result is bound to a variable, we need
to update the map with a new abstract value that is the result of merging the
old abstract value and the new value given by the analysis.
In theory, if all that we care about in the analysis is the mapping of call
sites to function identifiers, we could use a simple domain for the
value map ($\mathcal{V}$) based on just the powerset of the function identifiers.
Unfortunately, this domain is insufficiently precise in practice because of the presence of
tuples and datatypes.
Furthermore, SML treats all functions has having a single parameter, which means that
function arguments are packed into tuples at call sites and then extracted in the function
body.
Thus, the domain of abstract values needs to support tracking of information as it moves
into and out of more complicated data structures.

We build a lattice over these abstract values using the $\top$ and $\bot$ 
elements as usual, and treating values of \lstinline{TUPLE} and 
\lstinline{LAMBDAS} type as incomparable.
When two \lstinline{LAMBDAS} values are compared, the subset relationship 
provides an ordering.
It is this ordering that allows us to incrementally merge flow information, up
to a finite limit.
The most interesting portion of our implementation is in the merging of
two \lstinline{TUPLE} values.
In the trivial recursive solution, the analysis may fail to terminate because of
the presence of recursive datatypes (\eg{}, on each iteration over a function
that calls the \lstinline{cons} function, we will wrap another \lstinline{TUPLE}
value around the previous value).
In practice for typical Standard ML programs, we have found that limiting the
tracked depth to 5 and then mapping any further additions to $\top$
results in a good balance of performance and precision.

Note that unlike some other analyses, such as sub-zero CFA~\cite{sub-zero-cfa}, we do not limit the
maximum number of tracked functions per variable.
Avoiding this restriction allows us to use the results of our analysis to support
optimizations that can still be performed when multiple functions flow
to the same call site (unlike inlining).
Furthermore, we have found that reducing the number of tracked function variables has no measurable
impact on the runtime of the analysis, but it removes many optimization 
opportunities (\eg, calling convention optimization across a set of common functions).

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "paper"
%%% End: 
